{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# DigitalVidya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Week-2 Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dir_path=os.path.join(os.path.abspath('..'),'D:\\\\')\n",
    "file_path = os.path.join(dir_path, 'voice.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 1. Load the \"voice.csv\" dataset and perform feature extraction by using \"label\" as target column\n",
    "import os as os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dir_path=os.path.join(os.path.abspath('..'),'D:\\\\')\n",
    "file_path=os.path.join(dir_path,'voice.csv')\n",
    "voice=pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...    centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...    0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...    0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...    0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...    0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...    0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000      1  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632      1  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512      1  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119      1  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "voice['label']=le.fit_transform(voice['label'])\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>0.083878</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>0.104261</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  0.000000  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  0.000000  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  0.000000  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  0.083878  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  0.104261  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= voice['label'].tolist()\n",
    "x=voice.drop('label',axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05978098,  0.06424127,  0.03202691, ...,  0.0078125 ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.06600874,  0.06731003,  0.04022873, ...,  0.0546875 ,\n",
       "         0.046875  ,  0.05263158],\n",
       "       [ 0.0773155 ,  0.08382942,  0.03671846, ...,  0.015625  ,\n",
       "         0.0078125 ,  0.04651163],\n",
       "       ..., \n",
       "       [ 0.14205626,  0.09579843,  0.18373124, ...,  2.9375    ,\n",
       "         2.9296875 ,  0.19475862],\n",
       "       [ 0.14365874,  0.09062826,  0.18497617, ...,  3.59375   ,\n",
       "         3.5859375 ,  0.31100218],\n",
       "       [ 0.16550895,  0.09288354,  0.18304392, ...,  0.5546875 ,\n",
       "         0.546875  ,  0.35      ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
    "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
    "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x1=voice[['meanfreq','sd','centroid','meanfun','minfun','maxfun']]\n",
    "x1\n",
    "y1=voice['label'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x2=voice[['Q25','IQR','meanfun']]\n",
    "y2=voice['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 2. Split the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.75,random_state=0)\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.78394573e+00   3.53514949e+00   1.81828806e+00   1.39771956e+01\n",
      "   3.52467444e-02   2.63377445e+01   2.43295831e+01   1.19875979e+04\n",
      "   1.72251697e+00   3.12468496e+01   3.36984309e+00   1.78394573e+00\n",
      "   1.60943523e+01   5.93977241e-01   3.06702676e-01   3.84602285e+01\n",
      "   9.16278043e+00   2.97819019e+02   2.90272018e+02   2.46748091e-01]\n"
     ]
    }
   ],
   "source": [
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "test = SelectKBest(score_func=chi2, k=20)\n",
    "fit = test.fit(x,y)\n",
    "importance2=print(fit.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1_train,x1_test,y1_train,y1_test=train_test_split(x1,y1,test_size=.75,random_state=0)\n",
    "x1_train=np.array(x1_train)\n",
    "y1_train=np.array(y1_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x2_train,x2_test,y2_train,y2_test=train_test_split(x2,y2,test_size=.75,random_state=0)\n",
    "x2_train=np.array(x2_train)\n",
    "y2_train=np.array(y2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 3. Build a Logistic Regression classifier to detect the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegression=LogisticRegression()\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe=RFE(logisticRegression,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logisticRegression.fit(x1_train,y1_train)\n",
    "predictions2=logisticRegression.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegression.fit(x2_train,y2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions3=logisticRegression.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 4. Check performances by using different number of features. Find the best set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator \n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91119528619528622"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y2_test,predictions3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The most important features for logistic regression by selecting first 3 features using RFE   are q25,IQR and meanfun we get 91% accuracy in prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "  n_features_to_select=3, step=1, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rfe.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False], dtype=bool)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  8,  9,  1,  5,  1, 17, 18,  2,  3,  6, 13,  1, 15,  4, 16,  7,\n",
       "       11, 12, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
       "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
       "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice[['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
    "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
    "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx']].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89436026936026936"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y1_test,predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91119528619528622"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2_test,predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 5. Build a KNN classifier to detect the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "trees_clf=ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 6. Check performances by using different number of features. Find the best set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04248283,  0.08737117,  0.01711684,  0.10722273,  0.01473619,\n",
       "        0.26230015,  0.01520213,  0.01459211,  0.04899658,  0.02218586,\n",
       "        0.02312534,  0.02719603,  0.21254333,  0.0134102 ,  0.00861024,\n",
       "        0.01378412,  0.0174316 ,  0.02608433,  0.01317303,  0.01243519])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance=trees_clf.feature_importances_\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
       "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
       "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurenames=x.columns\n",
    "featurenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IQR': 0.26230014865146173,\n",
       " 'Q25': 0.10722272738261363,\n",
       " 'Q75': 0.014736189603212491,\n",
       " 'centroid': 0.027196025975187433,\n",
       " 'dfrange': 0.013173033602737628,\n",
       " 'kurt': 0.014592113950348823,\n",
       " 'maxdom': 0.026084327193265238,\n",
       " 'maxfun': 0.0086102394203116436,\n",
       " 'meandom': 0.013784121325694874,\n",
       " 'meanfreq': 0.042482834833068063,\n",
       " 'meanfun': 0.21254333003930795,\n",
       " 'median': 0.01711684307561278,\n",
       " 'mindom': 0.017431600487361931,\n",
       " 'minfun': 0.013410195906565992,\n",
       " 'mode': 0.02312534385530559,\n",
       " 'modindx': 0.012435193653005949,\n",
       " 'sd': 0.087371168736244481,\n",
       " 'sfm': 0.022185858712760954,\n",
       " 'skew': 0.015202128246955318,\n",
       " 'sp.ent': 0.048996575348977514}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict=dict(zip(featurenames,importance))\n",
    "feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 5: IQR (0.262300)\n",
      "feature 12: meanfun (0.212543)\n",
      "feature 3: Q25 (0.107223)\n",
      "feature 1: sd (0.087371)\n",
      "feature 8: sp.ent (0.048997)\n",
      "feature 0: meanfreq (0.042483)\n",
      "feature 11: centroid (0.027196)\n",
      "feature 17: maxdom (0.026084)\n",
      "feature 10: mode (0.023125)\n",
      "feature 9: sfm (0.022186)\n",
      "feature 16: mindom (0.017432)\n",
      "feature 2: median (0.017117)\n",
      "feature 6: skew (0.015202)\n",
      "feature 4: Q75 (0.014736)\n",
      "feature 7: kurt (0.014592)\n",
      "feature 15: meandom (0.013784)\n",
      "feature 13: minfun (0.013410)\n",
      "feature 18: dfrange (0.013173)\n",
      "feature 19: modindx (0.012435)\n",
      "feature 14: maxfun (0.008610)\n"
     ]
    }
   ],
   "source": [
    "feature_dict=dict(zip(featurenames,importance))\n",
    "sorted_features=sorted(feature_dict.items(),key=operator.itemgetter(1),reverse=True)\n",
    "indices=np.argsort(importance)[::-1]\n",
    "for f in range(x.shape[1]):\n",
    "     print(\"feature %d: %s (%f)\"%(indices[f],sorted_features[f][0],sorted_features[f][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 7. Find and plot the best value for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Knn=KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knn.fit(x2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=Knn.predict(x2_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_test=np.array(y2_test)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96338383838383834"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knn.score(x2_test,y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_range=range(1,26)\n",
    "scores=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963383838384\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x2_train, y2_train)\n",
    "y_pred = knn.predict(x2_test)\n",
    "print(metrics.accuracy_score(y2_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x2_train, y2_train)\n",
    "    y_pred = knn.predict(x2_test)\n",
    "    scores.append(metrics.accuracy_score(y2_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95580808080808077, 0.95580808080808077, 0.96801346801346799, 0.96170033670033672, 0.96338383838383834, 0.96338383838383834, 0.96464646464646464, 0.96338383838383834, 0.96254208754208759, 0.96254208754208759, 0.96296296296296291, 0.96338383838383834, 0.96338383838383834, 0.96254208754208759, 0.96170033670033672, 0.96170033670033672, 0.96170033670033672, 0.96170033670033672, 0.96170033670033672, 0.96254208754208759, 0.96085858585858586, 0.96085858585858586, 0.96127946127946129, 0.96085858585858586, 0.96127946127946129]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xc3c7160>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niXPOuZh4IHHOOReT/x/28Xk0W2cgnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc383358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "The best value of K is 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
